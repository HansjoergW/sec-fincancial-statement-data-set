Todos
------

New Release
- adapt readme
- adapt notebooks
- in gitpages branch
    - adapt release notes
    - adapt index
- adapt releases in project.toml
- merge back into main
- set tag and push tag
- on github -> under code releases: draft new release


v.1.5.0
- SumUpRule: additional parameter optional_summands
- Standardizer: new PrePivotRules are possible
    -> deduplication is added to PrePivotRule
    -> deduplication-log is part of the PrePivotRule log

v.1.4.2 ?
- fix für StandardStatementPresenter

Todo:
- Es werden PrePivotRuls benötigt
  Hier ist noch die Frage, wie man mit den Logs umgehen soll. Evtl. macht
  es sinn, dass ein einziges Log erstellt wird, mit einer neuen Spalte, welche die Regel ID enthält.
  Wenn wir quasi alle vorhandenen 'adsh', 'coreg', 'report', 'tag', 'uom', 'version', 'ddate'
  ins log aufnehmen, dann werden dass sehr viele Zeilen (mehre Millionen). Das könnte ein Problem sein.
  Man könnte auch so loggen und dann erst am Schluss pivotieren., falls man das möchte.
  Also: ein log, dass immer mit einträgen erweitert wird


- Es wird eine PrePivot Regel mit eigenem Log benötigt.
  Erste Regel, die angewendet werdne muss, ist sicherzustellen, dass das value für gewisse Tag
  entweder positiv oder negativ ist.
- die neue Regel muss auch für BalanceSheet nachdefiniert werden.

- Standardizer muss auch qtrs berücksitigen, entsprechend muss der Pivot Key
  auch qtrs berücksichtigen.
  -> Achtung der Key ist überall present, z.B. auch beim Handling von duplication
- eine prePivot regel sollte auch qtrs korrigieren können. z.B. sollte für BS infos immer nur
  qtrs 0 vorhanen sein, bzw. sollte auf 0 korrigiert werden, falls 10-k und gleich 4, oder
  ja nach analyse der vorhanden qtrs werte für 10-q



ToCheck:
- In der Thesis wurde IS entweder basierend auf IS oder CI berechnet
- in der Thesis habe ich beim Filtern noch auf die qtrs info geachtet,
  evtl. müsste man das hier auch überprüfen, bzw. einen entsprechenden Filter verwenden,
  bzw. als "PRE" Rule / Filter einfügen

            bs_mask    = (all_df.stmt == 'BS') & (all_df.period == all_df.ddate) & (all_df.qtrs == 0)

            is_ci_mask = all_df.stmt.isin(['IS', 'CI']) & (all_df.period == all_df.ddate) & (
                                            ((all_df.form == '10-K') & (all_df.qtrs == 4))
                                         |  ((all_df.form == '10-Q') & (all_df.qtrs == 1))
                                                            )

            # Generally: a CF for a quarterly report contains almost always the values from the beginning
            # of the financial year up to the end of the current quarter.
            # Sometimes, also just the information for that current quarter is present as well.
            # Seldom, only the current Quarter is present.
            cf_mask = (all_df.stmt == 'CF') & (all_df.period == all_df.ddate) & (
                             (all_df.tag == 'CashAndCashEquivalentsAtCarryingValue')
                         |   ((all_df.form == '10-K') & (all_df.qtrs == 4))
                         |   (
                              (all_df.form == '10-Q') & (
                                                     ((all_df.fp == 'Q1') & (all_df.qtrs == 1))
                                                   | ((all_df.fp == 'Q2') & (all_df.qtrs == 2))
                                                   | ((all_df.fp == 'Q3') & (all_df.qtrs == 3))
                                                   | ((all_df.fp == 'Q4') & (all_df.qtrs == 4))
                                                          )






todo:
- evtl. sollte jede Regel noch eine "Explanation" bekommen. Ein Text, der die Regel spezifisch erklärt,
  nicht allgemein wie in description.

Next:
- vlt switch um parallele verarbeitung komplett auszuschalten?
- vlt switch maximale parallelität?

- new notebook, examples
  -> reading primary financial statements for a single report, display BS, IS, CF for a report
  -> analyse changes in one Tag for one company
  -> compare basic data of two companies

- Supporting Dataset with notes -> V.2

- Es wäre gut, wenn der StandardStatementPresenter noch eine Kolonne "year", noch welcher auch sortiert ist
  die sortierung über adsh alleine ermöglicht keine sauber sortierung pro jahr
  man könnte hierfür auch das report year aus sub verwenden

- Pipelines: einfaches Konzept um Standard Flows zu kapseln
  z.B. Collector als Input bis zur Presentation
  -> z.B. für selektierte ciks daten so aufbereiten, dass sie alle vorhandenen Jahre in Spalten angezeigt werden

- transform methode, z.b. um zu homogenisieren

- update des config files
  fehlende Inhalte müssen gesetzt und auf default gesetzt werden, oder?
  überflüssige Inhalte müssen entfernt werden
  -> Im Moment noch nicht notwendig -> würde erst notwendig, falls
     Optionen nicht mehr benützt werden

- in company collector -> eine sicht für sämtlich Jahre zeigen -> mit Jahren als spalten, aber
   - versuchen die selben Tags zu zeigen, notfalls mit null...
   - reihenfolge könnte ein problem sein

- - warning, falls daten nicht indexiert sind
    -> Hinweis Message beim Laden der Config
    -> config for autocheck to download / autodownload

- using sourcery ai to improve code
  -> see PR in Fork https://github.com/pikki622/sec-fincancial-statement-data-set/pulls

later
-build timeline for company
-correct quarter naming -> was meine ich damit?
-db-version for updates


build, release & docu
- coverage report padge

Checkout für Visualisierung
- https://gist.github.com/mwouts/a2de16feb90d33fd89334fb09f62742f
- https://www.linkedin.com/pulse/interactive-dataframes-jupyter-google-colab-vs-code-pycharm-wouts/?trk=articles_directory
- https://pbpython.com/dataframe-gui-overview.html


Ideen
-----
- export excel
- cli
- https://streamlit.io/ ui


look at
-------
- https://pypi.org/project/edgartools/1.6.0/

