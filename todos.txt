todos
------

new release
- adapt readme
- adapt notebooks
- in gitpages branch
    - adapt release notes
    - adapt index
- adapt releases in project.toml
- merge back into main
- set tag and push tag (format vx.x.x)
- on github -> under code releases: draft new release


v.2.0.0 -> goal: ensure segment information is available
- (ok) only load new datasets
- (ok) ensure new dataset version can be downloaded and processed

- (ok) add info when storing data of processed file has_segments exists
- (ok) adapt testdata to use new datasets

- (ok) update testdata
- (ok) fix tests so that new datasets are supported

- (ok) ensure new files are there with segments info and the info is available in the bags
- (ok) add check which zip has new dataset
       -> display warning message, if not all zip files contain the new column

- (ok) new no_segmentinfo filter for raw and joined

- (ok) ensure join works correctly
       pre_num_df = joined_bag.pre_num_df[joined_bag.pre_num_df.stmt=='BS']
       sorted_pre_num_df = pre_num_df.sort_values(['adsh', 'ddate', 'report', 'line'])[['adsh','ddate', 'report', 'line', 'coreg', 'segments','tag', 'version', 'uom','value','plabel']]

- notebook quickstart / readme
  - [ok] ensure output in StandardPresenter is ok
    -> show_segments flag -> if False -> filters out segments
  - [ok] ensure Standardizer is working
    - fix standardizer by always applying NoSegmentsInfo Filter before pivot

- [ok] ensure data in searching notebook is presented correctly
    -> show_segments option in explore notebook

- [ok] ensure tests and linting is ok
  -> it looks as if the current downloaded data have the hasSegments columns in the sqlite table.
     -> Tests example is failing: test_collector/testexamples.py fails when zip collector is tested

- [ok] remove (temporary) rapid-api support

- check notebooks
  - [ok] 01_quickstart
  - [ok] 03_explore_..
    -> added show_segments flag when showing details of a single report
  - [ok] 04_collector_deep_dive
  - [ok] 05_filter_deep_dive
  - [ok] 06_bulk_data_..
    -> note: less data than before for CP> only a few hundred entries for dei / SharesOutstanding
  - [ok] 07_00_standardizer_basics
  - [ok] 07_01_BS..
  - [ok] 07_02_IS..
  - [ok] 07_03_CF..
  - 07_04_customize
  - 08_00_automation

- overwork Readme

- add specific test for StandardPresenter and standardizer
  -> check results against real report

- maybe introduce a first notebook explaining segments and what they show with examples

- check pipelines with larget datasets / memory usage

- adapt article medium

-----
2.0.1
- maybe also provide segmentsinfo per Tag? kind of overview
- improve concat logic -> directly use fastparquet to concat files, not using pandas
- maybe special "concat files to file"
- Flatten Segments -> general, which axis, per tag,
   - think about having a new databag -> segmentbag
   - would we need some special metadata?
   - for instance if you want to join a dataset?


2.0.2
- adapt standardizer, use segment infos



----------

- overwrite serial execution per task
- in cf haben wir oft auch zusätzliche 'cash' tags -> benötigen wir diese im bs auch?
- maxqtr prepivot rule also for bs und is

- standardize oustanding shares, resp. validate
  (see: https://github.com/hansjoergw/sec-fincancial-statement-data-set/issues/13)
  "but as i understand, they do not have the same exact meaning. i haven't investigated that, so i am not sure if you
  can assume that they are the same, resp. close enough to treat them that way. in the cp, the value appears
  as entitycommonstocksharesoutstanding (if present), in the balance sheet as commonstocksharesoutstanding,
  and in the incomestatement as weightedaveragenumberofsharesoutstandingbasic."

  -> adding entitycommonstocksharesoutstanding from cp
  -> adding commonstocksharesoutstanding to bs
  -> provide default handling of choosing which value for final "outstandingshares"



- discord channel?
- evtl. sollte jede regel noch eine "explanation" bekommen. ein text, der die regel spezifisch erklärt,
  nicht allgemein wie in description.

- usecase/analyzes ausarbeiten und eigenes notebook mit beispielen

- idea: using configuration file as parameter or as option instead of only class:
  input medium feedback:
  "what do you think about letting update() and configurationmanager take config_file_name with default value ''?
  this seems to provide more explicit control. i know this would affect many functions which take config.
  how about replacing it by config_file_name?"


next:
- vlt switch um parallele verarbeitung komplett auszuschalten?
- vlt switch maximale parallelität?

- new notebook, examples
  -> reading primary financial statements for a single report, display bs, is, cf for a report
  -> analyse changes in one tag for one company
  -> compare basic data of two companies

- supporting dataset with notes -> v.2

- es wäre gut, wenn der standardstatementpresenter noch eine kolonne "year", noch welcher auch sortiert ist
  die sortierung über adsh alleine ermöglicht keine sauber sortierung pro jahr
  man könnte hierfür auch das report year aus sub verwenden

- pipelines: einfaches konzept um standard flows zu kapseln
  z.b. collector als input bis zur presentation
  -> z.b. für selektierte ciks daten so aufbereiten, dass sie alle vorhandenen jahre in spalten angezeigt werden

- update des config files
  fehlende inhalte müssen gesetzt und auf default gesetzt werden, oder?
  überflüssige inhalte müssen entfernt werden
  -> im moment noch nicht notwendig -> würde erst notwendig, falls
     optionen nicht mehr benützt werden

- in company collector -> eine sicht für sämtlich jahre zeigen -> mit jahren als spalten, aber
   - versuchen die selben tags zu zeigen, notfalls mit null...
   - reihenfolge könnte ein problem sein

- - warning, falls daten nicht indexiert sind
    -> hinweis message beim laden der config
    -> config for autocheck to download / autodownload


later
-build timeline for company
-correct quarter naming -> was meine ich damit?
-db-version for updates


build, release & docu
- coverage report padge

checkout für visualisierung
- https://gist.github.com/mwouts/a2de16feb90d33fd89334fb09f62742f
- https://www.linkedin.com/pulse/interactive-dataframes-jupyter-google-colab-vs-code-pycharm-wouts/?trk=articles_directory
- https://pbpython.com/dataframe-gui-overview.html


ideen
-----
- export excel
- cli
- https://streamlit.io/ ui


look at
-------
- https://pypi.org/project/edgartools/1.6.0/

