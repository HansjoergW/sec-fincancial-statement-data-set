{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5974588b-0809-468d-b6e3-e2df73afaacd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# ensure that all columns are shown and that colum content is not cut\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width',1000)\n",
    "pd.set_option('display.max_rows', 500) # ensure that all rows are shown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333f3746-2750-4526-a4d9-b97ca6a1e167",
   "metadata": {},
   "source": [
    "# Bulk Data Processing\n",
    "The main advantage of this library is that the all data is downloaded down to your computer and therefore makes to analyze the whole datasets as a whole. For instance if you want to implement your own screener.\n",
    "\n",
    "Just on the file system, the size of all data files are more than 2 GB. Since the parquet format is also storage optimized, loading all the data into memory would need significantly more memory than a standard computer/laptop does provide.\n",
    "\n",
    "Hence it is important to filter the data during the loading process.\n",
    "\n",
    "So in this notebook, we will create different datasets for the balance sheet datapoints, the cashflow datapoints, and the income statement datapoints.\n",
    "These datasets will be stored in their own directories, so that they can be easily loaded afterwards. Moreover, we will store the raw version (where the num_df and the pre_df are not joined) and the joined version, where num_df and pre_df are joined.\n",
    "\n",
    "This notebook will show two approaches. The first one is loading all the data in parallel, if you enough resources in your computer. The second is doing it sequentially, which is slower, but needs less memory.\n",
    "\n",
    "We will also apply different filters:\n",
    "\n",
    "* only filter 10-K, 10-Q reports during loading\n",
    "* `ReportPeriodRawFilter`: since we are only interested in datapoints that belong to the period of the report\n",
    "* `MainCoregRawFilter`: since we don't want to see datapoints of a subsidiary\n",
    "* `OfficialTagsOnlyRawFilter`: since we want to be able to compare the content and therefore don't want to read tags that or not in the standard sec xbrl definition\n",
    "* `USDOnlyRawFilter`: since we are not interested in money datapoints that are not in USD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1904d65-28df-47e1-9385-9b60098afc6e",
   "metadata": {},
   "source": [
    "## Basics\n",
    "First we will defines some basic stuff that is used by both approaches.\n",
    "We will start with the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0d01c1f-8479-4360-aab6-164068424126",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from secfsdstools.d_container.databagmodel import RawDataBag, JoinedDataBag\n",
    "from secfsdstools.e_collector.zipcollecting import ZipCollector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133b535c-9ad4-4b00-9d39-bdf3dad43663",
   "metadata": {},
   "source": [
    "Next, we define a filter function, that can defines the whole chain. As mentioned in the 04_collector_deep_dive.ipynt notebook, we have to define the imports inside the functionitself, if we want to use it in jupyter together with parallization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d908348-8e48-461f-a26c-ec0d0f2bbfd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def postloadfilter(databag: RawDataBag) -> RawDataBag:\n",
    "    from secfsdstools.e_filter.rawfiltering import ReportPeriodRawFilter, MainCoregRawFilter, OfficialTagsOnlyRawFilter, USDOnlyRawFilter\n",
    "\n",
    "\n",
    "    return databag[ReportPeriodRawFilter()][MainCoregRawFilter()][OfficialTagsOnlyRawFilter()][USDOnlyRawFilter()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c0eca-1a9b-4a3b-a853-7f610c77a383",
   "metadata": {},
   "outputs": [],
   "source": [
    "Next is a simple \n",
    "\n",
    "save raw, join and save joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9395fe8a-06c3-4ca4-9953-fc22fa58b9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_databag(databag: RawDataBag, financial_statement: str, base_path: str):\n",
    "    target_path_raw = os.path.join(base_path, financial_statement, 'raw')\n",
    "    os.makedirs(target_path_raw, exist_ok=True)\n",
    "    databag.save(target_path_raw)\n",
    "    \n",
    "    target_path_joined = os.path.join(base_path, financial_statement, 'joined')\n",
    "    os.makedirs(target_path_joined, exist_ok=True)\n",
    "    joined_databag = databag.join()\n",
    "    joined_databag.save(target_path_joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c564ba5e-3334-47a9-94c7-53ba5df7a9c5",
   "metadata": {},
   "source": [
    "## Parallel Data Loading\n",
    "As stated above, we want to load all available 10-K and 10-Q reports. Therefore, we can use the `ZipCollector`which provides a option to load data from all available zip files. \n",
    "\n",
    "Moreover, the implementation of the ziploader does using all your cores in order to load data from your disk into memory. So you don't have to implement the parallization yourself. There are 50+ zip files that have to be loaded, so if you have 4 cores, you will load 4 at one time.\n",
    "\n",
    "Also, the `ZipCollector` provides parameters for filtering the report type (10-K and 10-Q) amd the financial statement type (Balance Sheet, Casch Flow, or Income Statement) which are directly applied during loading, since we have the data stored in Parquet format. This will already reduce that amount of data that is being loaded into memory significantly.\n",
    "\n",
    "Moreover, it also provides the post_load_filter which we can use to apply the other filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18ac72e-0020-4ea5-9cd8-373e2f143fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_financial_statements_parallel(financial_statement: str) -> RawDataBag:\n",
    "    \"\"\" \n",
    "    financial_statement: either \"BS\", \"CF\", or \"IS\"\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "\n",
    "    collector: ZipCollector = ZipCollector.get_all_zips(forms_filter=[\"10-K\", \"10-Q\"],\n",
    "                                                        stmt_filter=[financial_statement],\n",
    "                                                        post_load_filter=postloadfilter)\n",
    "\n",
    "    return collector.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b158ec71-ce9d-49ea-9a23-6f111fcc8811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa354406-bd41-4c3d-8879-7a9cb3ac1f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54335992-07ea-4077-ac8e-081bd17281f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686cf90c-fe3e-4f28-a987-42d5961695fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56220514-4cdf-41e3-b553-4d25f6d8aaeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a329dd9d-1108-4cf8-9ff3-5fb2ded59127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452b18df-500a-448c-9485-71bd44c7717b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbd23fa-0a51-4733-8d85-be5d39e19e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e30588-40df-4acf-af50-f588cd2e0ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fdc620-20d7-4d3b-9294-9b1b696241e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f566bf-0422-40dc-8d2f-b2bce2a842c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd8b9c1-022a-4a79-b51d-94d6decbe591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
