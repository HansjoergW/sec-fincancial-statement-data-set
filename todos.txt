Todos
------

New Release
- adapt readme
- adapt release notes
- adapt notebooks
- adapt releases in project.toml
- merge back into main


v.1.0.0
- DataBag
- collectors producing DataBags
- searching moved from e_read to c_index
- companyreading moved from e_read to c_index as companyindexreading / CompanyIndexReader
- Filter in eigene Fitlerklassen ausgelagert

Next:

- das ganze basis testing muss sauber neu aufgeräumt werden
- für die tests sollte man ein zentrales fixture haben, welches die configuration erzeugt,
  so dass diese für die Tests verwendet werden kann, ohne dass jedesmal eine neue config gelesen,
  oder aber die "richtige" config gelesen wird
  oder ich benötige ein konzept, wie das organsiert werden soll

- Presentation Pivots
  -> zuerst alte Logik komplett integrieren


- Pipelines: einfaches Konzept um Standard Flows zu kapseln
  z.B. Collector als Input bis zur Presentation


direktes parquet filtern ist etwa 10% schneller, nicht wirklich viel, vor allem weil
der code einiges komplizierter wird
Was man noch testen könnte ist wenn stmts und tags auch gefiltert werden?


Filter ist ein einfaches interface -> kann verkettet werden
fitler Methode auf Bag, Nimmt direkt Filter auf

 "filter(self, filter: RawFilter) -> RawDataBag"


- Wie und wo filtern wir für period, previous period, tags..?
- fitern wir auf raw, oder auch auf joined?
- was liefern filter zurück? ein neues df (copy), oder nur das gefilterte?
- oder sind filter so gar auf collector möglich? so dass man direkt beim parquet lesen filtern kann?
- bzw.,  was sind spezial filter für period und previous period?



next
- update des config files
  fehlende Inhalte müssen gesetzt und auf default gesetzt werden, oder?
  überflüssige Inhalte müssen entfernt werden
  -> Im Moment noch nicht notwendig -> würde erst notwendig, falls
     Optionen nicht mehr benützt werden

- in company collector -> eine sicht für sämtlich Jahre zeigen -> mit Jahren als spalten, aber
   - versuchen die selben Tags zu zeigen, notfalls mit null...
   - reihenfolge könnte ein problem sein

- export load function, oder cache for MultiReportReader..
- - warning, falls daten nicht indexiert sind
    -> Hinweis Message beim Laden der Config
    -> config for autocheck to download / autodownload

- using sourcery ai to improve code
  -> see PR in Fork https://github.com/pikki622/sec-fincancial-statement-data-set/pulls

later
-build timeline for company
-correct quarter naming -> was meine ich damit?
-parquet support
-db-version for updates

features
- Example Notebooks
  - example report reading
  - example zip reading
  - example extension -> z.B. db access / erweiteren reader

build, release & docu
- coverage report padge
- release to readthedocs



Checkout für Visualisierung
- https://gist.github.com/mwouts/a2de16feb90d33fd89334fb09f62742f
- https://www.linkedin.com/pulse/interactive-dataframes-jupyter-google-colab-vs-code-pycharm-wouts/?trk=articles_directory
- https://pbpython.com/dataframe-gui-overview.html

Ideen
-----
- export excel
- cli
- https://streamlit.io/ ui


look at
-------
- https://pypi.org/project/edgartools/1.6.0/

